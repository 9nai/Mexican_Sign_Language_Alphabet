{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CLASIFICACIÓN DE IMÁGENES CON LENGUA DE SEÑAS.\n",
        "Aguilar Guzmán Naomi Betel\n",
        "416089231 \\\\\n",
        "BD: https://kaggle.com/datamunge/sign-language-mnist"
      ],
      "metadata": {
        "id": "LrW38bAx017j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import time\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.preprocessing import image\n",
        "import os\n",
        "import glob\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.utils import plot_model\n",
        "from keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l1\n",
        "import shutil"
      ],
      "metadata": {
        "id": "I0QuOz5xbLXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero accedemos al drive donde esta la base de datos y las imagenes de muestra:"
      ],
      "metadata": {
        "id": "WzZTsU-mLU7B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWSJpsyKqHjH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_path = 'gdrive/Mi unidad/Base de datos/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La base de datos se encuentra en formato csv. La columna 'label' encontramos las etiquetas de las imagenes, la etiqueta es un numero del  al 25, a manera de: 0 es A, 1 es B y etc. El resto de las columnas contienen un valor del 0 al 255 que representa el color de los pixeles, por lo que hay 28*28=784 columnas.\n"
      ],
      "metadata": {
        "id": "x25jyU5a41tO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Base de datos/sign_mnist_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Base de datos/sign_mnist_test.csv')\n",
        "train = train.sample(frac=1)\n",
        "test = test.sample(frac=1)\n",
        "train"
      ],
      "metadata": {
        "id": "6jYDQ5TLz54z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "isYf8774rHVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos una lista para las etiquetas de las letras como string, para facilitar la visualizacion de los datos:"
      ],
      "metadata": {
        "id": "CddDG3zTOBGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M','N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y','Z']"
      ],
      "metadata": {
        "id": "yM6us8mR2Hd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora pasamos la base de datos a un formao de numpy:"
      ],
      "metadata": {
        "id": "tuRPqY5zOhSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.array(train, dtype = 'float32')\n",
        "test_data = np.array(test, dtype = 'float32')"
      ],
      "metadata": {
        "id": "qvLtqHaM10wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "lYHRvsgEmKNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "MfZIV2MbnQgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XAOv9pVeonLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('TIPOS DE CLASE')\n",
        "print('Imprime la clase de train:', type(train))\n",
        "print('Imprime la clase de test:', type(test))\n",
        "\n",
        "print('TAMAÑO')\n",
        "print('Dimensiones de train', train.shape)\n",
        "print('Dimensiones de test', test.shape)\n",
        "\n",
        "print('PORCENTAJES')\n",
        "total=test.shape[0]+train.shape[0]\n",
        "print('Tenemos ', total, 'imágenes en total.')\n",
        "print('El porcentaje de imágenes de entrenamiento es: ', train.shape[0]/total)\n",
        "print('El porcentaje de imágenes de prueba es: ', test.shape[0]/total)"
      ],
      "metadata": {
        "id": "Q8QquL8Ujt9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos una muestra aleatoria de los elementos de la base de datos. Como se observa, es una imagen de 28x28 pixeles en escala de grises con su respectiva etiqueta:"
      ],
      "metadata": {
        "id": "-FianXtyP5W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = random.randint(1,train.shape[0])\n",
        "fig1, ax1 = plt.subplots(figsize=(2,2))\n",
        "plt.imshow(train_data[i,1:].reshape((28,28)), cmap='gray')\n",
        "print(\"Esta letras es: \", class_names[int(train_data[i,0])])"
      ],
      "metadata": {
        "id": "FAYtppnx2Nx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora hacemos un histograma para ver la distribucion de las muestras. Como se observa, las muestras son en general balanceadas."
      ],
      "metadata": {
        "id": "LXO8N5XsQksA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(0,25):\n",
        "  train['label'].replace({i:class_names[i]},inplace=True)\n",
        "fig = plt.figure(figsize=(18,18))\n",
        "ax1 = fig.add_subplot(221)\n",
        "train['label'].value_counts().plot(kind='bar', ax=ax1)\n",
        "ax1.set_ylabel('Train')\n",
        "ax1.set_xlabel('Letra')\n",
        "ax1.set_title('Histograma de la base de datos')\n",
        "\n",
        "for i in range(0,25):\n",
        "  test['label'].replace({i:class_names[i]},inplace=True)\n",
        "fig = plt.figure(figsize=(18,18))\n",
        "ax1 = fig.add_subplot(221)\n",
        "test['label'].value_counts().plot(kind='bar', ax=ax1)\n",
        "ax1.set_ylabel('Test')\n",
        "ax1.set_xlabel('Letra')\n",
        "ax1.set_title('Histograma de la base de datos')"
      ],
      "metadata": {
        "id": "_6HsaD4VEK6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora separamos normalizamos la base de datos y usamos reshape para ponerla en formato (27455,28,28,1) pues hay 27455 imagenes de 28*28 pixeles y en escala de grises."
      ],
      "metadata": {
        "id": "HTUrZP2ERzXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_data[:, 1:] /255\n",
        "x_test = test_data[:, 1:] /255\n",
        "x_train = x_train.reshape(x_train.shape[0], 28 ,28 ,1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28 , 1)\n",
        "x_train.shape"
      ],
      "metadata": {
        "id": "5MsbWmgzT4cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_data[:, 0]\n",
        "y_test = test_data[:,0]\n",
        "y_train"
      ],
      "metadata": {
        "id": "K1IDOetwUz5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora preparamos la estructura de una red convolutiva:"
      ],
      "metadata": {
        "id": "IoC-M8FscVWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "\n",
        "model1.add(Conv2D(32, (3, 3), input_shape = (28,28,1), activation='relu'))\n",
        "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(Conv2D(128, (3, 3), activation='relu',bias_regularizer=l1(0.05)))\n",
        "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(Conv2D(128, (1, 1), activation='relu',bias_regularizer=l1(0.05)))\n",
        "model1.add(MaxPooling2D(pool_size = (1, 1)))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "model1.add(Flatten())\n",
        "\n",
        "model1.add(Dense(128, activation = 'sigmoid'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(25, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "2j1d69_EV200"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esquema del modelo implementado"
      ],
      "metadata": {
        "id": "fRvfVS-1lAp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model1, to_file = 'mnist_signal.png', show_shapes = True, rankdir = 'TB', show_layer_names = True)"
      ],
      "metadata": {
        "id": "ATubDbWZlErE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora compilamos el modelo y mostramos sus parámetros:\n",
        "\n",
        "> Bloque con sangría\n",
        "\n"
      ],
      "metadata": {
        "id": "3CUOGpSGcmlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model1.compile(loss ='sparse_categorical_crossentropy', optimizer='adam', metrics =['accuracy'])\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "SdGTQKV2YbrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenando el modelo:"
      ],
      "metadata": {
        "id": "DZ9RX_Rwcuea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(x_train, y_train, batch_size = 128, epochs = 20, verbose = 1, validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "id": "eYCvqrIVaAlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora graficamos train loss y el validation loss para verificar que no haya sobreenrenamiento:"
      ],
      "metadata": {
        "id": "Kad9qzxDc0kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GRAFICAMOS\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(history.history['loss'], color = 'green')\n",
        "plt.plot(history.history['val_loss'], color = 'red')\n",
        "plt.ylabel('Cost', size = 16)\n",
        "plt.xlabel('Epoch', size = 16)\n",
        "plt.legend(['Train', 'Validation'], loc = 'upper right', fontsize = 16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CHzY4nReabGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRAFICAMOS\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(history.history['accuracy'], color = 'green')\n",
        "plt.plot(history.history['val_accuracy'], color = 'blue')\n",
        "plt.ylabel('Accuracy', size = 16)\n",
        "plt.xlabel('Epoch', size = 16)\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower right', fontsize = 16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FTD-Cn0zwqAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EVALUACION\n",
        "evaluations = model1.evaluate(x = x_test[:], y = y_test[:])\n",
        "print (\"Loss:\" + str(evaluations[0]))\n",
        "print (\"Test Accuracy:\" + str(evaluations[1]))"
      ],
      "metadata": {
        "id": "r7hdztKz2Z1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora hacemos una prediccion sobre los datos de prueba, para verificar que letras son las que son peor clasificadas y graficamos un hisograma con el porcenaje de muestras mal clasificadas:"
      ],
      "metadata": {
        "id": "qoDz5q0fdLKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model1.predict(x_test)\n",
        "classes_x=np.argmax(prediction,axis=1)\n",
        "\n",
        "count1=[0 for i in class_names]\n",
        "i=0\n",
        "while i<len(y_test):\n",
        "  count1[int(y_test[i])]+=1\n",
        "  i+=1\n",
        "\n",
        "count2=[0 for i in class_names]\n",
        "i=0\n",
        "while i<len(classes_x):\n",
        "  if int(classes_x[i]) != int(y_test[i]):\n",
        "    count2[int(y_test[i])]+=1\n",
        "  i+=1\n",
        "\n",
        "comp=[]\n",
        "i=0\n",
        "while i<len(class_names):\n",
        "  if count1[i] !=0:\n",
        "    comp.append([i,(count2[i]/count1[i])*100])\n",
        "  else:\n",
        "    comp.append([i,0])\n",
        "  i+=1\n",
        "\n",
        "comp.sort(key=lambda x: -x[1])\n",
        "class_label=[class_names[int(comp[i][0])] for i in range(0,len(class_names))]\n",
        "\n",
        "comp=pd.DataFrame(comp)\n",
        "for i in range(0,25):\n",
        "  comp[0].replace({i:class_names[i]},inplace=True)\n",
        "\n",
        "fig = plt.figure(figsize=(18,18))\n",
        "ax1 = fig.add_subplot(221)\n",
        "comp.plot(kind='bar', ax=ax1)\n",
        "ax1.set_xticklabels(class_label)\n",
        "ax1.set_ylabel('Clasificaciones incorrectas (%)')\n",
        "ax1.set_xlabel('Letra')\n",
        "ax1.set_title('Histograma de letras mal clasificadas')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LyTbLQCihpCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora tomamos una muestra aleatoria de la base de datos y checamos que prediccion da el modelo:"
      ],
      "metadata": {
        "id": "8-90aT81d6o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = random.randint(0,len(prediction)-1)\n",
        "plt.imshow(x_test[i,:,:,0])\n",
        "print(\"Letra Predecida: \", class_names[int(classes_x[i])])\n",
        "print(\"Letra Verdadera: \", class_names[int(y_test[i])])"
      ],
      "metadata": {
        "id": "aSr-NSOAc9MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter=0\n",
        "\n",
        "while True:\n",
        "  i = random.randint(0,len(prediction)-1)\n",
        "  counter+=1\n",
        "\n",
        "  if class_names[int(y_test[i])]!=class_names[int(classes_x[i])]:\n",
        "    print(\"Después de \", counter, 'intentos hubo una predicción errónea.\\n')\n",
        "    plt.imshow(x_test[i,:,:,0])\n",
        "    print(\"Letra Predecida: \", class_names[int(classes_x[i])])\n",
        "    print(\"Letra Verdadera: \", class_names[int(y_test[i])])\n",
        "    break"
      ],
      "metadata": {
        "id": "tOxE7YLlzB__"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}